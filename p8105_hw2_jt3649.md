p8105_hw2_jt3649
================
Juan Tang
2025-10-01

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.4     ✔ readr     2.1.5
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.1
    ## ✔ ggplot2   3.5.2     ✔ tibble    3.3.0
    ## ✔ lubridate 1.9.4     ✔ tidyr     1.3.1
    ## ✔ purrr     1.1.0     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
library(readxl)
```

## Problem 1

### Import datasets.

Read in and clean the pols-month dataset and clean the names.

``` r
pols_month_df = 
  read_csv("data/pols-month.csv")
```

    ## Rows: 822 Columns: 9
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl  (8): prez_gop, gov_gop, sen_gop, rep_gop, prez_dem, gov_dem, sen_dem, r...
    ## date (1): mon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
pols_month_df = 
  #use clean_name function in the janitor package
  janitor::clean_names(pols_month_df) |>
  #use separate() to break up the variable mon. 
  separate(mon, into = c("year", "month", "day"), sep = "-") |>
  mutate(
    #change the month number to name
    month = as.numeric(month),
    month = month.name[month], 
    #convert year variable to numeric value
    year = as.numeric(year),
    #add president variable
    president = ifelse(prez_gop == 1, "gop", "dem")
  ) |>
  #remove prez_dem, prez_gop, day variable
  select(-prez_dem, -prez_gop, -day) |>
  #arrange the year, month order
  arrange(year, month)
```

Read in and clean the snp dataset and clean the names.

``` r
snp_df = 
  read_csv("data/snp.csv")
```

    ## Rows: 787 Columns: 2
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (1): date
    ## dbl (1): close
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
snp_df = 
  #use clean_name function in the janitor package
  janitor::clean_names(snp_df) |>
  #use separate() to break up the variable mon. 
  separate(date, into = c("month", "day", "year"), sep = "/") |>
  mutate(
    #change the month number to name
    month = as.numeric(month),
    month = month.name[month],
    #change the year variable to numeric number
    year = as.numeric(year), 
    #unify the year variable format 
    year = ifelse(year < 50, year + 2000, year + 1900)
    ) |>
  #remove day variable
  select(-day) |>
  #arrange the year, month order
  arrange(year, month)
```

Read in and clean the unemployment dataset

``` r
unemployment_df = 
  read_csv("data/unemployment.csv") |>
  pivot_longer(
    #select all columns except "Year" to pivot
    cols = -Year, 
    #put the columns names into a new column "month"
    names_to = "month", 
    #put the unemployment_rate values into a new column "unemployment_rate"
    values_to = "unemployment_rate"
  ) |>
  mutate(
    #match the month abbreviation with month name
    month = month.name[match(month, month.abb)], 
    #match the column name year
    year = Year
  ) |>
  select(year, month, unemployment_rate) |>
  #arrange the year, month variable in order
  arrange(year, month)
```

    ## Rows: 68 Columns: 13
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (13): Year, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

### Merge the datasets

``` r
merged_data_p1 = pols_month_df |>
  #merge snp into pols
  left_join(snp_df, by = c("year", "month")) |>
  #merge unemployment into pols and snp dataset
  left_join(unemployment_df, by = c("year", "month"))
```

This is the merged dataset:

``` r
print(merged_data_p1)
```

    ## # A tibble: 822 × 11
    ##     year month   gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem president close
    ##    <dbl> <chr>     <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>     <dbl>
    ##  1  1947 April        23      51     253      23      45     198 dem          NA
    ##  2  1947 August       23      51     253      23      45     198 dem          NA
    ##  3  1947 Decemb…      24      51     253      23      45     198 dem          NA
    ##  4  1947 Februa…      23      51     253      23      45     198 dem          NA
    ##  5  1947 January      23      51     253      23      45     198 dem          NA
    ##  6  1947 July         23      51     253      23      45     198 dem          NA
    ##  7  1947 June         23      51     253      23      45     198 dem          NA
    ##  8  1947 March        23      51     253      23      45     198 dem          NA
    ##  9  1947 May          23      51     253      23      45     198 dem          NA
    ## 10  1947 Novemb…      24      51     253      23      45     198 dem          NA
    ## # ℹ 812 more rows
    ## # ℹ 1 more variable: unemployment_rate <dbl>

### Description of the dataset

The `pols_month` dataset contained information about the political party
affiliation of national politicians from 1947 to 2015. It included 822
observations and variables indicating the number of Republican and
Democratic governors, senators, and representatives, as well as the
party of the president at each time point.

The `snp` dataset contained information about the Standard & Poor’s
stock market index (S&P) from 1950 to 2015. It included 787 observations
of the closing value of the S&P index, and it serves as a representative
measure of stock market performance.

The `unemployment` dataset contained monthly unemployment rates from
1948 to 2015. It included 816 observations showing the percentage of
unemployment for each month and year.

The final merged dataset contains 822 observations and 11 variables from
1947 to 2015. Key variables include year, month, gov_gop, sen_gop,
rep_gop, gov_dem, sen_dem, rep_dem, president, close, unemployment_rate.
This merged dataset allows for analysis of the relationships between
political composition of government, stock market performance, and
unemployment rates over time.

## Problem 2

## Problem 2

Read and clean the Mr. Trash Wheel data sheet

``` r
mr_trash_wheel_df = 
  read_excel("data/202509 Trash Wheel Collection Data.xlsx",
             sheet = "Mr. Trash Wheel", 
             #include only columns with data
             range = cell_cols("A:N"), 
             #skip the first row which contains a figure
             skip = 1
             ) |>
  janitor::clean_names() |>
  #remove rows without dumpster data
  filter(!is.na(dumpster)) |>
  mutate(
    #round the number of sports balls to the nearest integer
    sports_balls = as.integer(round(sports_balls, 0)), 
    year = as.numeric(year),
    #add identifier variable
    trash_wheel = "Mr. Trash Wheel"
  )
#number of observations in the mr_trash_wheel dataset
cat("Mr. Trash Wheel observations: ", nrow(mr_trash_wheel_df))
```

    ## Mr. Trash Wheel observations:  707

Read and clean the Professor Trash Wheel data sheet

``` r
prof_trash_wheel_df = 
  read_excel("data/202509 Trash Wheel Collection Data.xlsx",
             sheet = "Professor Trash Wheel", 
             #include only columns with data
             range = cell_cols("A:M"), 
             #skip the first row which contains a figure
             skip = 1
             ) |>
  janitor::clean_names() |>
  #remove rows without dumpster data
  filter(!is.na(dumpster)) |>
  mutate(
    #there is no sports_ball variable in the sheet
    sports_balls = NA_integer_, 
    #unify date formate
    date = as.Date(date),
    year = as.numeric(year),
    #add identifier variable
    trash_wheel = "Professor Trash Wheel"
  )
#number of observations in the prof_trash_wheel dataset
cat("Professor Trash Wheel observations: ", nrow(prof_trash_wheel_df))
```

    ## Professor Trash Wheel observations:  132

Read and clean the gwynns trash wheel data sheet

``` r
gwynns_trash_wheel_df = 
  read_excel("data/202509 Trash Wheel Collection Data.xlsx",
             sheet = "Gwynns Falls Trash Wheel", 
             #include only columns with data
             range = cell_cols("A:L"), 
             #skip the first row which contains a figure
             skip = 1
             ) |>
  janitor::clean_names() |>
  #remove rows without dumpster data
  filter(!is.na(dumpster)) |>
  mutate(
    #there is no sports_ball variable in the sheet
    sports_balls = NA_integer_, 
    date = as.Date(date),
    year = as.numeric(year),
    #add identifier variable
    trash_wheel = "Gwynns Trash Wheel"
  )
#number of observations in the gwynns_trash_wheel dataset
cat("Gwynns Trash Wheel observations: ", nrow(gwynns_trash_wheel_df))
```

    ## Gwynns Trash Wheel observations:  349

### Combine datasets

``` r
combined_trash_wheel = bind_rows(mr_trash_wheel_df, prof_trash_wheel_df, gwynns_trash_wheel_df) |>
  arrange(trash_wheel, date)
```

### Dataset summary

The combined dataset has 1188 observations. Example variables include
dumpster, month, year, date, weight_tons, volume_cubic_yards,
plastic_bottles, polystyrene, cigarette_butts, glass_bottles,
plastic_bags, wrappers, sports_balls, homes_powered, trash_wheel.

### Total weight of trash collected by Professor Trash Wheel

``` r
prof_total_weight = combined_trash_wheel |>
  filter(trash_wheel == "Professor Trash Wheel") |>
  summarise(total_weight = sum(weight_tons, na.rm = TRUE)) |>
  pull(total_weight)
prof_total_weight
```

    ## [1] 282.26

Total weight of trash collected by Professor Trash Wheel is 282.26 tons.

### Cigarette Butts Collected by Gwynns in June 2022

``` r
gwynns_cigarette_june_2022 = combined_trash_wheel |>
  filter(
    trash_wheel == "Gwynns Trash Wheel", 
    year(date) == 2022, 
    month(date) == 6
  ) |>
  summarize(total_cig = sum(cigarette_butts, na.rm = TRUE)) |>
  pull(total_cig)
gwynns_cigarette_june_2022
```

    ## [1] 18120

Cigarette Butts Collected by Gwynns in June 2022 are 1.812^{4}.

## Problem 3

### Import and clean data

``` r
#Import rental price data
rental_price_df = read_csv("data/zillow_data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv") |>
  janitor::clean_names()
```

    ## Rows: 149 Columns: 125
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr   (6): RegionType, StateName, State, City, Metro, CountyName
    ## dbl (119): RegionID, SizeRank, RegionName, 2015-01-31, 2015-02-28, 2015-03-3...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
#Import zip code data
zip_code_df = read_csv("data/zillow_data/Zip Codes.csv") |>
  janitor::clean_names()
```

    ## Rows: 322 Columns: 7
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (4): County, County Code, File Date, Neighborhood
    ## dbl (3): State FIPS, County FIPS, ZipCode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Tidy rental price dataset

``` r
#The data is in wide format with dates as columns. Pivot it to long format. 
rental_price_tidy = rental_price_df |>
  pivot_longer(
    #"\\d{4}" means matches exactly 4 digits (year)
    #"\\d{2}" means matches exactly 2 digits (month/day)
    col = starts_with("x") | matches ("^\\d{4}_\\d{2}_\\d{2}$"), 
    #set the name of the variable(column) to "date"
    names_to = "date", 
    #add "price" variable
    values_to = "price"
  ) |>
  #tidy the "date" variable
  mutate(
    #remove "x" prefix before the date
    date = str_remove(date, "x"), 
    #replace "_" with "-"
    date = str_replace_all(date, "_", "-"), 
    date = as.Date(date)
  ) |>
  rename("zip_code" = "region_name")|>
  #standardize the county names in rental_price
  mutate(
    county_name = str_remove(county_name, "County$"), 
    county_name = case_when(
      county_name == "New York" ~ "New York", 
      county_name == "Kings" ~ "Kings", 
      county_name == "Queens" ~ "Queens", 
      county_name == "Bronx" ~ "Bronx", 
      county_name == "Richmond" ~ "Richmond", 
      TRUE ~ county_name
      )
  )
nrow(rental_price_tidy)
```

    ## [1] 17284

Tidy zip code dataset

``` r
zip_code_tidy = zip_code_df |>
  mutate(
    #add a borough column from county
    borough = case_when(
      str_detect(county, "New York") ~ "Manhattan", 
      str_detect(county, "Kings") ~ "Brooklyn", 
      str_detect(county, "Queens") ~ "Queens",
      str_detect(county, "Bronx") ~ "Bronx", 
      str_detect(county, "Richmond") ~ "Staten Island", 
      TRUE ~ NA_character_
    ), 
    #unify the county names in zip_code_tidy
    county = case_when(
      str_detect(county, "New York") ~ "New York", 
      str_detect(county, "Kings") ~ "Kings", 
      str_detect(county, "Queens") ~ "Queens",
      str_detect(county, "Bronx") ~ "Bronx", 
      str_detect(county, "Richmond") ~ "Richmond", 
      TRUE ~ county
      )
  )
nrow(zip_code_tidy)
```

    ## [1] 322

### Merge datasets

``` r
merged_data = rental_price_tidy |>
  left_join(
    zip_code_tidy, 
    by = "zip_code"
  ) |>
  arrange(borough, neighborhood, zip_code, date)
```

    ## Warning in left_join(rental_price_tidy, zip_code_tidy, by = "zip_code"): Detected an unexpected many-to-many relationship between `x` and `y`.
    ## ℹ Row 4757 of `x` matches multiple rows in `y`.
    ## ℹ Row 256 of `y` matches multiple rows in `x`.
    ## ℹ If a many-to-many relationship is expected, set `relationship =
    ##   "many-to-many"` to silence this warning.

``` r
cat("This is the merged dataset: ")
```

    ## This is the merged dataset:

``` r
merged_data
```

    ## # A tibble: 17,516 × 18
    ##    region_id size_rank zip_code region_type state_name state city     metro     
    ##        <dbl>     <dbl>    <dbl> <chr>       <chr>      <chr> <chr>    <chr>     
    ##  1     61798        63    10458 zip         NY         NY    New York New York-…
    ##  2     61798        63    10458 zip         NY         NY    New York New York-…
    ##  3     61798        63    10458 zip         NY         NY    New York New York-…
    ##  4     61798        63    10458 zip         NY         NY    New York New York-…
    ##  5     61798        63    10458 zip         NY         NY    New York New York-…
    ##  6     61798        63    10458 zip         NY         NY    New York New York-…
    ##  7     61798        63    10458 zip         NY         NY    New York New York-…
    ##  8     61798        63    10458 zip         NY         NY    New York New York-…
    ##  9     61798        63    10458 zip         NY         NY    New York New York-…
    ## 10     61798        63    10458 zip         NY         NY    New York New York-…
    ## # ℹ 17,506 more rows
    ## # ℹ 10 more variables: county_name <chr>, date <date>, price <dbl>,
    ## #   county <chr>, state_fips <dbl>, county_code <chr>, county_fips <dbl>,
    ## #   file_date <chr>, neighborhood <chr>, borough <chr>

### Dataset summary

``` r
n_observations = nrow(merged_data)
n_unique_zips = n_distinct(merged_data$zip_code)
n_unique_neighborhoods = n_distinct(merged_data$neighborhood, na.rm = TRUE)
date_range = range(merged_data$date)
cat("Total observations: ", n_observations)
```

    ## Total observations:  17516

``` r
cat("Unique Zip codes: ", n_unique_zips)
```

    ## Unique Zip codes:  149

``` r
cat("Unique neighborhoods: ", n_unique_neighborhoods)
```

    ## Unique neighborhoods:  42

``` r
cat("Date range: ", format(date_range[1]), "to", format(date_range[2]))
```

    ## Date range:  2015-01-31 to 2024-08-31

The final tidy dataset contains 17516 observations representing monthly
rental price data for 149 unique ZIP codes. The dataset includes 42
unique neighborhoods in New York City. The data spans from 2015-01-31 to
2024-08-31. Each observation represents the Zillow Observed Rent Index
(ZORI) for a specific ZIP code on a specific date.

### Zip codes in zip_code dataset but not in rental_price dataset

``` r
missing_zip = zip_code_tidy |>
  anti_join(
    rental_price_tidy, 
    by = c("zip_code")
  ) |>
  select(zip_code, borough, neighborhood) |>
  arrange(borough, neighborhood)
missing_zip
```

    ## # A tibble: 171 × 3
    ##    zip_code borough  neighborhood              
    ##       <dbl> <chr>    <chr>                     
    ##  1    10474 Bronx    Hunts Point and Mott Haven
    ##  2    10475 Bronx    Northeast Bronx           
    ##  3    10464 Bronx    Southeast Bronx           
    ##  4    10499 Bronx    <NA>                      
    ##  5    10550 Bronx    <NA>                      
    ##  6    10704 Bronx    <NA>                      
    ##  7    10705 Bronx    <NA>                      
    ##  8    10803 Bronx    <NA>                      
    ##  9    11239 Brooklyn Canarsie and Flatlands    
    ## 10    11224 Brooklyn Southern Brooklyn         
    ## # ℹ 161 more rows

``` r
cat("Number of zip codes missing from Zillow data but included in zip_code data: ", nrow(missing_zip))
```

    ## Number of zip codes missing from Zillow data but included in zip_code data:  171

Example of missing zip codes:

``` r
cat("Sample of ZIP Codes Missing from Zillow Dataset:\n\n")
```

    ## Sample of ZIP Codes Missing from Zillow Dataset:

``` r
head(missing_zip, 15)
```

    ## # A tibble: 15 × 3
    ##    zip_code borough  neighborhood              
    ##       <dbl> <chr>    <chr>                     
    ##  1    10474 Bronx    Hunts Point and Mott Haven
    ##  2    10475 Bronx    Northeast Bronx           
    ##  3    10464 Bronx    Southeast Bronx           
    ##  4    10499 Bronx    <NA>                      
    ##  5    10550 Bronx    <NA>                      
    ##  6    10704 Bronx    <NA>                      
    ##  7    10705 Bronx    <NA>                      
    ##  8    10803 Bronx    <NA>                      
    ##  9    11239 Brooklyn Canarsie and Flatlands    
    ## 10    11224 Brooklyn Southern Brooklyn         
    ## 11    11202 Brooklyn <NA>                      
    ## 12    11241 Brooklyn <NA>                      
    ## 13    11242 Brooklyn <NA>                      
    ## 14    11243 Brooklyn <NA>                      
    ## 15    11245 Brooklyn <NA>

### Using a few illustrative examples discuss why these ZIP codes might be excluded from the Zillow dataset.

1.  Based on the sample of missing ZIP codes, some of them have “NA” for
    neighborhood (eg. 10499, 10550, 10704, 10705, 10803). For example,
    ZIP code 10499 locates in the Bronx and it serves the Co-op City
    neighborhood, which is unique for a large residential complex, not a
    traditional geographical area. Also, 10550 is located in Mount
    Vernon, Westchester County, NY. It is a city bordering NYC but not
    part of it. This ZIP code may have been incorrectly included n the
    NYC ZIP code dataset.
2.  For those ZIP code with neighborhood information, the missing from
    zillow dataset may due to the low rental market activity.

### Compare rental prices in January 2021 to prices in January 2020

``` r
#filter for Jan 2020 and Jan 2021
covid_compare = merged_data |>
  filter(
    (year(date) == 2020 & month(date) == 1) | 
    (year(date)) == 2021 & month(date) == 1) |>
  select(zip_code, borough, neighborhood, date, price) |>
  #pivot wider to compare the two time points
  pivot_wider(
    names_from = date, 
    values_from = price
  )

jan_2020_col = names(covid_compare) [str_detect(names(covid_compare), "2020-01")]
jan_2021_col = names(covid_compare) [str_detect(names(covid_compare), "2021-01")]

#rename for clarity
covid_compare = covid_compare |>
  rename(
    price_jan_2020 = all_of(jan_2020_col), 
    price_jan_2021 = all_of(jan_2021_col)
  ) |>
  #remove rows with missing data
  filter(!is.na(price_jan_2020) & !is.na(price_jan_2021)) |>
  #calculate price changes
  mutate(
    price_change = price_jan_2021 - price_jan_2020, 
    pct_change = (price_change/price_jan_2020)*100
  )
```

Top 10 drop in rental price during covid

``` r
top_10_drops = covid_compare |>
  arrange(price_change) |>
  slice_head(n=10) |>
  select(
    zip_code, 
    borough, 
    neighborhood, 
    price_jan_2020, 
    price_jan_2021, 
    price_change, 
    pct_change
  )
```

Display the table:

``` r
cat("Top 10 ZIP Codes with Largest Rental Price Drops (Jan 2020 to Jan 2021)")
```

    ## Top 10 ZIP Codes with Largest Rental Price Drops (Jan 2020 to Jan 2021)

``` r
top_10_drops |>
  mutate(
    #add units, round to the nearest integer (price), round to one decimal place (percent change)
    price_jan_2020 = scales::dollar(price_jan_2020, accuracy = 1), 
    price_jan_2021 = scales::dollar(price_jan_2021, accuracy = 1),
    price_change = scales::dollar(price_change, accuracy = 1), 
    pct_change = paste0(round(pct_change, 1), "%")
  )
```

    ## # A tibble: 10 × 7
    ##    zip_code borough   neighborhood    price_jan_2020 price_jan_2021 price_change
    ##       <dbl> <chr>     <chr>           <chr>          <chr>          <chr>       
    ##  1    10007 Manhattan Lower Manhattan $6,334         $5,422         -$913       
    ##  2    10069 Manhattan <NA>            $4,623         $3,875         -$748       
    ##  3    10009 Manhattan Lower East Side $3,406         $2,692         -$714       
    ##  4    10016 Manhattan Gramercy Park … $3,731         $3,019         -$712       
    ##  5    10001 Manhattan Chelsea and Cl… $4,108         $3,398         -$710       
    ##  6    10002 Manhattan Lower East Side $3,645         $2,935         -$710       
    ##  7    10004 Manhattan Lower Manhattan $3,150         $2,444         -$706       
    ##  8    10038 Manhattan Lower Manhattan $3,573         $2,876         -$698       
    ##  9    10012 Manhattan Greenwich Vill… $3,629         $2,942         -$686       
    ## 10    10010 Manhattan Gramercy Park … $3,697         $3,012         -$685       
    ## # ℹ 1 more variable: pct_change <chr>

### Comment on price drop during covid

From the table, it is observed that the largest price drops are mostly
located in Manhattan, especially neighborhoods that were traditionally
popular. This geographic concentration suggests that the pandemic
affected the rental market with high density and high-cost (eg. lower
Manhattan). Due to pandemic, many people work remotely. They likely
relocated to less expensive areas or larger space outside the city
center. During the pandemic’s peak, dense urban environment were
perceived as higher risk. Residents tend to move to less crowded areas.
The drop in rental price can be contributed to various factors such as
the remote work feasibility, health concerns about urban density, and
the decreasing demand of urban facilities during covid.
