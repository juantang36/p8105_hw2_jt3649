---
title: "p8105_hw2_jt3649"
author: "Juan Tang"
date: "`r Sys.Date()`"
output: github_document
---

```{r setup}
library(tidyverse)
library(readxl)
```


## Problem 1
### Import datasets. 

Read in and clean the pols-month dataset and clean the names. 
```{r}
pols_month_df = 
  read_csv("data/pols-month.csv")
pols_month_df = 
  #use clean_name function in the janitor package
  janitor::clean_names(pols_month_df) |>
  #use separate() to break up the variable mon. 
  separate(mon, into = c("year", "month", "day"), sep = "-") |>
  mutate(
    #change the month number to name
    month = as.numeric(month),
    month = month.name[month], 
    #convert year variable to numeric value
    year = as.numeric(year),
    #add president variable
    president = ifelse(prez_gop == 1, "gop", "dem")
  ) |>
  #remove prez_dem, prez_gop, day variable
  select(-prez_dem, -prez_gop, -day) |>
  #arrange the year, month order
  arrange(year, month)
```

Read in and clean the snp dataset and clean the names. 
```{r}
snp_df = 
  read_csv("data/snp.csv")
snp_df = 
  #use clean_name function in the janitor package
  janitor::clean_names(snp_df) |>
  #use separate() to break up the variable mon. 
  separate(date, into = c("month", "day", "year"), sep = "/") |>
  mutate(
    #change the month number to name
    month = as.numeric(month),
    month = month.name[month],
    #change the year variable to numeric number
    year = as.numeric(year), 
    #unify the year variable format 
    year = ifelse(year < 50, year + 2000, year + 1900)
    ) |>
  #remove day variable
  select(-day) |>
  #arrange the year, month order
  arrange(year, month)
```

Read in and clean the unemployment dataset
```{r}
unemployment_df = 
  read_csv("data/unemployment.csv") |>
  pivot_longer(
    #select all columns except "Year" to pivot
    cols = -Year, 
    #put the columns names into a new column "month"
    names_to = "month", 
    #put the unemployment_rate values into a new column "unemployment_rate"
    values_to = "unemployment_rate"
  ) |>
  mutate(
    #match the month abbreviation with month name
    month = month.name[match(month, month.abb)], 
    #match the column name year
    year = Year
  ) |>
  select(year, month, unemployment_rate) |>
  #arrange the year, month variable in order
  arrange(year, month)
```

### Merge the datasets
```{r}
merged_data_p1 = pols_month_df |>
  #merge snp into pols
  left_join(snp_df, by = c("year", "month")) |>
  #merge unemployment into pols and snp dataset
  left_join(unemployment_df, by = c("year", "month"))
```

This is the merged dataset: 
```{r}
print(merged_data_p1)
```

### Description of the dataset
The `pols_month` dataset contained information about the political party affiliation of national politicians from `r min(pols_month_df$year)` to `r max(pols_month_df$year)`. It included `r nrow(pols_month_df)` observations and variables indicating the number of Republican and Democratic governors, senators, and representatives, as well as the party of the president at each time point.

The `snp` dataset contained information about the Standard & Poorâ€™s stock market index (S&P) from `r min(snp_df$year)` to `r max(snp_df$year)`. It included `r nrow(snp_df)` observations of the closing value of the S&P index, and it serves as a representative measure of stock market performance.

The `unemployment` dataset contained monthly unemployment rates from `r min(unemployment_df$year)` to `r max(unemployment_df$year)`. It included `r nrow(unemployment_df)` observations showing the percentage of unemployment for each month and year.

The final merged dataset contains `r nrow(merged_data_p1)` observations and `r ncol(merged_data_p1)` variables from `r min(merged_data_p1$year)` to `r max(merged_data_p1$year)`. Key variables include `r paste(names(merged_data_p1), collapse = ", ")`. 
This merged dataset allows for analysis of the relationships between political composition of government, stock market performance, and unemployment rates over time.


## Problem 2

### Read and clean datasets

Read and clean the Mr. Trash Wheel data sheet
```{r mr trash wheel}
mr_trash_wheel_df = 
  read_excel("data/202509 Trash Wheel Collection Data.xlsx",
             sheet = "Mr. Trash Wheel", 
             #include only columns with data
             range = cell_cols("A:N"), 
             #skip the first row which contains a figure
             skip = 1
             ) |>
  janitor::clean_names() |>
  #remove rows without dumpster data
  filter(!is.na(dumpster)) |>
  mutate(
    #round the number of sports balls to the nearest integer
    sports_balls = as.integer(round(sports_balls, 0)), 
    year = as.numeric(year),
    #add identifier variable
    trash_wheel = "Mr. Trash Wheel"
  )
#number of observations in the mr_trash_wheel dataset
cat("Mr. Trash Wheel observations: ", nrow(mr_trash_wheel_df))
```

Read and clean the Professor Trash Wheel data sheet 
```{r prof trash wheel}
prof_trash_wheel_df = 
  read_excel("data/202509 Trash Wheel Collection Data.xlsx",
             sheet = "Professor Trash Wheel", 
             #include only columns with data
             range = cell_cols("A:M"), 
             #skip the first row which contains a figure
             skip = 1
             ) |>
  janitor::clean_names() |>
  #remove rows without dumpster data
  filter(!is.na(dumpster)) |>
  mutate(
    #there is no sports_ball variable in the sheet
    sports_balls = NA_integer_, 
    #unify date formate
    date = as.Date(date),
    year = as.numeric(year),
    #add identifier variable
    trash_wheel = "Professor Trash Wheel"
  )
#number of observations in the prof_trash_wheel dataset
cat("Professor Trash Wheel observations: ", nrow(prof_trash_wheel_df))
```

Read and clean the gwynns trash wheel data sheet 
```{r gwynns}
gwynns_trash_wheel_df = 
  read_excel("data/202509 Trash Wheel Collection Data.xlsx",
             sheet = "Gwynns Falls Trash Wheel", 
             #include only columns with data
             range = cell_cols("A:L"), 
             #skip the first row which contains a figure
             skip = 1
             ) |>
  janitor::clean_names() |>
  #remove rows without dumpster data
  filter(!is.na(dumpster)) |>
  mutate(
    #there is no sports_ball variable in the sheet
    sports_balls = NA_integer_, 
    date = as.Date(date),
    year = as.numeric(year),
    #add identifier variable
    trash_wheel = "Gwynns Trash Wheel"
  )
#number of observations in the gwynns_trash_wheel dataset
cat("Gwynns Trash Wheel observations: ", nrow(gwynns_trash_wheel_df))
```

### Combine datasets
```{r combine datasets}
combined_trash_wheel = bind_rows(mr_trash_wheel_df, prof_trash_wheel_df, gwynns_trash_wheel_df) |>
  arrange(trash_wheel, date)
```

### Dataset summary

This dataset contains information about trash collected by three water-wheel vessels that remove trash from the Inner Harbor in Baltimore, Maryland. The combined dataset has `r nrow(combined_trash_wheel)` observations and `r ncol(combined_trash_wheel)` variables. The dataset includes data from `r min(combined_trash_wheel$year)` to `r max(combined_trash_wheel$year)`.  Variables include specific type of trash, date, total weight of trash, and dumpster, which is the identifier for each dumpster load. 
Variables in the merged dataset are: `r paste(names(combined_trash_wheel), collapse = ", ")`.



### Total weight of trash collected by Professor Trash Wheel
```{r professor weight}
prof_total_weight = combined_trash_wheel |>
  filter(trash_wheel == "Professor Trash Wheel") |>
  summarise(total_weight = sum(weight_tons, na.rm = TRUE)) |>
  pull(total_weight)
prof_total_weight
```
Total weight of trash collected by Professor Trash Wheel is `r prof_total_weight` tons. 

### Cigarette Butts Collected by Gwynns in June 2022
```{r}
gwynns_cigarette_june_2022 = combined_trash_wheel |>
  filter(
    trash_wheel == "Gwynns Trash Wheel", 
    year(date) == 2022, 
    month(date) == 6
  ) |>
  summarize(total_cig = sum(cigarette_butts, na.rm = TRUE)) |>
  pull(total_cig)
gwynns_cigarette_june_2022
```
Cigarette Butts Collected by Gwynns in June 2022 are `r gwynns_cigarette_june_2022`. 


## Problem 3
### Import and clean data
```{r}
#Import rental price data
rental_price_df = read_csv("data/zillow_data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv") |>
  janitor::clean_names()
#Import zip code data
zip_code_df = read_csv("data/zillow_data/Zip Codes.csv") |>
  janitor::clean_names()
```

Tidy rental price dataset
```{r rental price tidy}
#The data is in wide format with dates as columns. Pivot it to long format. 
rental_price_tidy = rental_price_df |>
  pivot_longer(
    #"\\d{4}" means matches exactly 4 digits (year)
    #"\\d{2}" means matches exactly 2 digits (month/day)
    col = starts_with("x") | matches ("^\\d{4}_\\d{2}_\\d{2}$"), 
    #set the name of the variable(column) to "date"
    names_to = "date", 
    #add "price" variable
    values_to = "price"
  ) |>
  #tidy the "date" variable
  mutate(
    #remove "x" prefix before the date
    date = str_remove(date, "x"), 
    #replace "_" with "-"
    date = str_replace_all(date, "_", "-"), 
    date = as.Date(date)
  ) |>
  rename("zip_code" = "region_name")|>
  #standardize the county names in rental_price
  mutate(
    county_name = str_remove(county_name, "County$"), 
    county_name = case_when(
      county_name == "New York" ~ "New York", 
      county_name == "Kings" ~ "Kings", 
      county_name == "Queens" ~ "Queens", 
      county_name == "Bronx" ~ "Bronx", 
      county_name == "Richmond" ~ "Richmond", 
      TRUE ~ county_name
      )
  )
nrow(rental_price_tidy)
```


Tidy zip code dataset
```{r zip code tidy}
zip_code_tidy = zip_code_df |>
  mutate(
    #add a borough column from county
    borough = case_when(
      str_detect(county, "New York") ~ "Manhattan", 
      str_detect(county, "Kings") ~ "Brooklyn", 
      str_detect(county, "Queens") ~ "Queens",
      str_detect(county, "Bronx") ~ "Bronx", 
      str_detect(county, "Richmond") ~ "Staten Island", 
      TRUE ~ NA_character_
    ), 
    #unify the county names in zip_code_tidy
    county = case_when(
      str_detect(county, "New York") ~ "New York", 
      str_detect(county, "Kings") ~ "Kings", 
      str_detect(county, "Queens") ~ "Queens",
      str_detect(county, "Bronx") ~ "Bronx", 
      str_detect(county, "Richmond") ~ "Richmond", 
      TRUE ~ county
      )
  )
nrow(zip_code_tidy)
```

### Merge datasets
```{r merged data}
merged_data = rental_price_tidy |>
  left_join(
    zip_code_tidy, 
    by = "zip_code"
  ) |>
  arrange(borough, neighborhood, zip_code, date)
cat("This is the merged dataset: ")
merged_data
```

### Dataset summary

```{r dataset summary}
n_observations = nrow(merged_data)
n_unique_zips = n_distinct(merged_data$zip_code)
n_unique_neighborhoods = n_distinct(merged_data$neighborhood, na.rm = TRUE)
date_range = range(merged_data$date)
cat("Total observations: ", n_observations)
cat("Unique Zip codes: ", n_unique_zips)
cat("Unique neighborhoods: ", n_unique_neighborhoods)
cat("Date range: ", format(date_range[1]), "to", format(date_range[2]))
```

The final tidy dataset contains `r format(n_observations)` observations representing monthly rental price data for `r n_unique_zips` unique ZIP codes. The dataset includes `r n_unique_neighborhoods` unique neighborhoods in New York City. 
The data spans from `r format(date_range[1])` to `r format(date_range[2])`. Each observation represents the Zillow Observed Rent Index (ZORI) for a specific ZIP code on a specific date.

### Zip codes in zip_code dataset but not in rental_price dataset
```{r}
missing_zip = zip_code_tidy |>
  anti_join(
    rental_price_tidy, 
    by = c("zip_code")
  ) |>
  select(zip_code, borough, neighborhood) |>
  arrange(borough, neighborhood)
missing_zip
cat("Number of zip codes missing from Zillow data but included in zip_code data: ", nrow(missing_zip))
```

Example of missing zip codes: 
```{r}
cat("Sample of ZIP Codes Missing from Zillow Dataset:\n\n")
head(missing_zip, 15)
```

### Using a few illustrative examples discuss why these ZIP codes might be excluded from the Zillow dataset.
1. Based on the sample of missing ZIP codes, some of them have "NA" for neighborhood (eg. 10499, 10550, 10704, 10705, 10803). 
For example, ZIP code 10499 locates in the Bronx and it serves the Co-op City neighborhood, which is unique for a large residential complex, not a traditional geographical area. Also, 10550 is located in Mount Vernon, Westchester County, NY. It is a city bordering NYC but not part of it. This ZIP code may have been incorrectly included n the NYC ZIP code dataset.
2. For those ZIP code with neighborhood information, the missing from zillow dataset may due to the low rental market activity.


### Compare rental prices in January 2021 to prices in January 2020
```{r covid_compare}
#filter for Jan 2020 and Jan 2021
covid_compare = merged_data |>
  filter(
    (year(date) == 2020 & month(date) == 1) | 
    (year(date)) == 2021 & month(date) == 1) |>
  select(zip_code, borough, neighborhood, date, price) |>
  #pivot wider to compare the two time points
  pivot_wider(
    names_from = date, 
    values_from = price
  )

jan_2020_col = names(covid_compare) [str_detect(names(covid_compare), "2020-01")]
jan_2021_col = names(covid_compare) [str_detect(names(covid_compare), "2021-01")]

#rename for clarity
covid_compare = covid_compare |>
  rename(
    price_jan_2020 = all_of(jan_2020_col), 
    price_jan_2021 = all_of(jan_2021_col)
  ) |>
  #remove rows with missing data
  filter(!is.na(price_jan_2020) & !is.na(price_jan_2021)) |>
  #calculate price changes
  mutate(
    price_change = price_jan_2021 - price_jan_2020, 
    pct_change = (price_change/price_jan_2020)*100
  )
```

Top 10 drop in rental price during covid
```{r top_10_drops}
top_10_drops = covid_compare |>
  arrange(price_change) |>
  slice_head(n=10) |>
  select(
    zip_code, 
    borough, 
    neighborhood, 
    price_jan_2020, 
    price_jan_2021, 
    price_change, 
    pct_change
  )
```

Display the table: 
```{r display_table}
cat("Top 10 ZIP Codes with Largest Rental Price Drops (Jan 2020 to Jan 2021)")
top_10_drops |>
  mutate(
    #add units, round to the nearest integer (price), round to one decimal place (percent change)
    price_jan_2020 = scales::dollar(price_jan_2020, accuracy = 1), 
    price_jan_2021 = scales::dollar(price_jan_2021, accuracy = 1),
    price_change = scales::dollar(price_change, accuracy = 1), 
    pct_change = paste0(round(pct_change, 1), "%")
  )
```

### Comment on price drop during covid
From the table, it is observed that the largest price drops are mostly located in Manhattan, especially neighborhoods that were traditionally popular. This geographic concentration suggests that the pandemic affected the rental market with high density and high-cost (eg. lower Manhattan). Due to pandemic, many people work remotely. They likely relocated to less expensive areas or larger space outside the city center. During the pandemic's peak, dense urban environment were perceived as higher risk. Residents tend to move to less crowded areas. 
The drop in rental price can be contributed to various factors such as the remote work feasibility, health concerns about urban density, and the decreasing demand of urban facilities during covid. 




